---
title: "ポテンシャル関数もうちょっと"
author: "ryamada"
date: "2021年5月19日"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## もうちょっと考えてみた

$$
P(\mathbf{X}=(x_1,...,x_L)|\mathbf{\Theta}) = exp(\mathbf{F(X)} \mathbf{\Theta} - \psi(\mathbf{\Theta}))\\
p(x_k|\mathbf{\Theta}) = exp(\mathbf{f}_k \cdot \mathbf{\Theta} - \psi(\Theta)),\\
\sum_{k=1}^L p(x_k|\mathbf{\Theta}) = 1
$$

ポテンシャル関数は

$$
\psi(\Theta) = \log{\sum_{k=1}^L exp(\mathbf{f}_k\cdot \mathbf{\Theta})}
$$

である。

この関数の凸性を調べる。

## 凸関数

$$
\forall u,v,\\
0 \le t < 1,\\
t f(u) + (1-t) f(v) \ge f(t u + (1-t)v)
$$

ただし、$t=\frac{1}{2}$に限って示しても、(おそらく)OK。

なぜならば、$t=\frac{1}{2}$での大小比較を繰り返すことで示せるから(多分)。


## ポテンシャル関数の凸性

$$
\frac{1}{2} f(\mathbf{u}) + \frac{1}{2}f(\mathbf{v}) - f(\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}) \ge 0,\\
\mathbf{u}, \mathbf{v} \in R^N,\\
f(\mathbf{w}) =\log{g(\mathbf{w})},\\
g(\mathbf{w}) = \sum_{k=1}^L exp(\mathbf{f}_k \cdot \mathbf{w}),\\
\mathbf{u},\mathbf{v},\mathbf{f}_k \in R^N
$$

を示したい。

式変形する。

$$
\frac{1}{2} f(\mathbf{u}) + \frac{1}{2}f(\mathbf{v}) - f(\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}) \ge 0,\\
\frac{1}{2} \log{g(\mathbf{u})} + \frac{1}{2}\log{g(\mathbf{v})} - \log{g(\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v})} \ge 0,\\
\log{\frac{g(\mathbf{u})^{\frac{1}{2}} g(\mathbf{v})^{\frac{1}{2}}} {g(\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}})}} \ge 0,\\
\frac{g(\mathbf{u})^{\frac{1}{2}} g(\mathbf{v})^{\frac{1}{2}}} {g(\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}})} \ge 1,\\
g(\mathbf{u})^{\frac{1}{2}} g(\mathbf{v})^{\frac{1}{2}} \ge g(\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}}) 
$$
両辺、正なので、両辺を二乗してもよいので
$$
g(\mathbf{u}) g(\mathbf{v}) \ge (g(\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}}) )^2
$$

$$
(\sum_{k1=1}^L exp( \mathbf{f}_{k1}\cdot \mathbf{u}))(\sum_{k2=1}^L exp(\mathbf{f}_{k2}\cdot \mathbf{v})) \ge (\sum_{k1=1}^L exp(\mathbf{f}_{k1}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}}))(\sum_{k2=1}^L exp( \mathbf{f}_{k2}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}}))
$$

両辺を展開した項数は $L^2$で等しい。

両辺の項は、$k1=k2$の場合と$k1 < k2$の場合と$k1 > k2$の場合とで尽くされる。

### $k1=k2$の場合

ある$k1=k2=\kappa$に関して
左辺
$$
 (exp(\mathbf{f}_{\kappa}\cdot \mathbf{u})\times  exp(\mathbf{f}_{\kappa}\cdot \mathbf{v})) =  exp(\mathbf{f}_{\kappa}\cdot (\mathbf{u}+\mathbf{v})) 
$$
右辺
$$
exp(\mathbf{f}_{\kappa}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}})) \times exp(\mathbf{f}_{\kappa}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}})) = exp(\mathbf{f}_{\kappa}\cdot (\mathbf{\mathbf{u}+\mathbf{v}}))
$$

$k1=k2$の項は、すべて、左辺と右辺で等しい。

### $k1 \ne k2$の場合

$k1 < k2$の場合と$k1 > k2$の場合のペアで考える。

$(k1,k2) = \{(\kappa_1,\kappa_2),(\kappa_2,\kappa_1)\}$

の項を考える。

左辺

$$
(exp(\mathbf{f}_{\kappa_1}\cdot \mathbf{u})\times  exp(\mathbf{f}_{\kappa_2}\cdot \mathbf{v})) + (exp(\mathbf{f}_{\kappa_2}\cdot \mathbf{u})\times  exp(\mathbf{f}_{\kappa_1}\cdot \mathbf{v})) \\
= exp(\mathbf{f}_{\kappa_1}\cdot \mathbf{u} + \mathbf{f}_{\kappa_2}\cdot \mathbf{v}) + exp(\mathbf{f}_{\kappa_2}\cdot \mathbf{u} + \mathbf{f}_{\kappa_1}\cdot \mathbf{v}) \\
= (exp(\frac{1}{2}(\mathbf{f}_{\kappa_1}\cdot \mathbf{u} + \mathbf{f}_{\kappa_2}\cdot \mathbf{v})))^2 + (exp(\frac{1}{2}(\mathbf{f}_{\kappa_2}\cdot \mathbf{u} + \mathbf{f}_{\kappa_1}\cdot \mathbf{v})))^2\\
= \text{左辺の式}
$$

右辺

$$
exp(\mathbf{f}_{\kappa_1}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}})) \times exp(\mathbf{f}_{\kappa_2}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}})) + exp(\mathbf{f}_{\kappa_2}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}})) \times exp(\mathbf{f}_{\kappa_1}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}})) \\
= 2 exp(\mathbf{f}_{\kappa_1}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}})) \times exp(\mathbf{f}_{\kappa_2}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}}))\\
= 2 exp((\mathbf{f}_{\kappa_1} + \mathbf{f}_{\kappa_2}) \cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}}))\\
= \text{右辺の式}
$$

ここで、以下を考える。

$$
(exp(\frac{1}{2}(\mathbf{f}_{\kappa_1}\cdot \mathbf{u} + \mathbf{f}_{\kappa_2}\cdot \mathbf{v}))- exp(\frac{1}{2}(\mathbf{f}_{\kappa_2}\cdot \mathbf{u} + \mathbf{f}_{\kappa_1}\cdot \mathbf{v})))^2
$$

これは$C^2$であるから0以上。

これを展開する。

$$
(exp(\frac{1}{2}(\mathbf{f}_{\kappa_1}\cdot \mathbf{u} + \mathbf{f}_{\kappa_2}\cdot \mathbf{v}))- exp(\frac{1}{2}(\mathbf{f}_{\kappa_2}\cdot \mathbf{u} + \mathbf{f}_{\kappa_1}\cdot \mathbf{v})))^2 \\
= (exp(\frac{1}{2}(\mathbf{f}_{\kappa_1}\cdot \mathbf{u} + \mathbf{f}_{\kappa_2}\cdot \mathbf{v})))^2 + (exp(\frac{1}{2}(\mathbf{f}_{\kappa_2}\cdot \mathbf{u} + \mathbf{f}_{\kappa_1}\cdot \mathbf{v})))^2 - 2 exp(\frac{1}{2}(\mathbf{f}_{\kappa_1}\cdot \mathbf{u} + \mathbf{f}_{\kappa_2}\cdot \mathbf{v}))\times exp(\frac{1}{2}(\mathbf{f}_{\kappa_2}\cdot \mathbf{u} + \mathbf{f}_{\kappa_1}\cdot \mathbf{v})) \\
\text{左辺の式} - \text{右辺の式} \ge 0
$$

以上から、
$$
\frac{1}{2} f(\mathbf{u}) + \frac{1}{2}f(\mathbf{v}) - f(\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}) \ge 0,\\
\mathbf{u}, \mathbf{v} \in R^N,\\
f(\mathbf{w}) =\log{g(\mathbf{w})},\\
g(\mathbf{w}) = \sum_{k=1}^L exp(\mathbf{f}_k \cdot \mathbf{w}),\\
\mathbf{u},\mathbf{v},\mathbf{f}_k \in R^N
$$
が成り立つ。


## 実験

$N \times L$ 行列を任意に作成し、
かつ、$\Theta$空間上の任意の２点$u,v$と、任意の実数$0 \ge t < 1$について、

$$
t f(\mathbf{u}) + (1-t)f(\mathbf{v}) - f(t\mathbf{u}+(1-t)\mathbf{v})
$$
の符号を調べてみる。

```{r}
L <- 200
N <- 9
n.trial <- 1000 # 試行回数
vals <- rep(0,n.trial)
for(i in 1:n.trial){
  Fx <- matrix(rnorm(L*N),ncol=L) * runif(1) * 3
  #Fx<- Fx/sqrt(apply(Fx^2,1,sum)) * runif(1) * 10
  u <- rnorm(N) * 5
  v <- rnorm(N) * 5
  t <- runif(1)
  
  # exp(Fu)
  exp_Fu = sum(exp(u %*% Fx))
  # exp(Fv)
  exp_Fv = sum(exp(v %*% Fx))
  # exp(F(tu + (1-t)v))
  exp_Fuv <- sum(exp((t * u+(1-t)*v) %*% Fx))
  
  vals[i] <- t*log(exp_Fu) +(1-t) * log(exp_Fv) - log(exp_Fuv)
}
```
```{r}
min(vals)
```
```{r}
plot(sort(vals))
```

## ポテンシャル関数の凸の様子

任意の点を通る、任意の直線に関する２階差分が正であることを実験する。

```{r}
L <- 200
N <- 9
t <- seq(from=-20,to=20,length=50)
n.trial <- 1000 # 試行回数
minslog<- rep(0,n.trial)
psis <- matrix(0,n.trial,length(t))
for(ii in 1:n.trial){

  
  Fx <- matrix(rnorm(L*N),ncol=L)
  Fx<- Fx/sqrt(apply(Fx^2,1,sum)) * runif(1) * 10
  
  V <- rnorm(N)
  V <- V/sqrt(sum(V^2))
  X0 <- rnorm(N) *10
  
  ret <- retlog <- t
  for(i in 1:length(t)){
    X <- X0 + t[i] * V
    tmp <- X %*% Fx #log(P)的な値
    ret[i] <- sum(exp(tmp)) # exp(psi)の値
  }
  retlog <- log(ret) # psiの値
  psis[ii,] <- retlog
  # ２階の差分
  minslog[ii] <- min(diff(diff(retlog)))
}


```


全試行の、二階の差分の最小値は実質的に、0で下限されている模様。

```{r}
min(minslog)
```

$psi(\theta)$の$\Theta$空間直線上の値の変化。

どれも凸に見える。

```{r}
matplot(t(psis),type="l")
```

試行ごとの、二階の差分の最小値が０下限に見える。

```{r}
plot(sort(minslog),ylim=c(0,max(minslog)))
```


## 検証２


$$
(\sum_{k1=1}^L exp( \mathbf{f}_{k1}\cdot \mathbf{u}))(\sum_{k2=1}^L exp(\mathbf{f}_{k2}\cdot \mathbf{v})) - (\sum_{k1=1}^L exp(\mathbf{f}_{k1}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}}))(\sum_{k2=1}^L exp( \mathbf{f}_{k2}\cdot (\mathbf{\frac{1}{2}\mathbf{u}+\frac{1}{2}\mathbf{v}}))\\
=\sum_{k1<k2}^{L,L}(exp(\frac{1}{2}(\mathbf{f}_{\kappa_1}\cdot \mathbf{u} + \mathbf{f}_{\kappa_2}\cdot \mathbf{v}))- exp(\frac{1}{2}(\mathbf{f}_{\kappa_2}\cdot \mathbf{u} + \mathbf{f}_{\kappa_1}\cdot \mathbf{v})))^2
$$

の確認。

```{r}
L <- 20
N <- 9
Fx <- matrix(rnorm(L*N),ncol=L) * runif(1) * 1
u <- rnorm(N) * 2
v <- rnorm(N) * 2
t <- 1/2

# exp(Fu)
exp_Fu = sum(exp(u %*% Fx))
# exp(Fv)
exp_Fv = sum(exp(v %*% Fx))
# exp(F(tu + (1-t)v))
exp_Fuv <- sum(exp((t * u+(1-t)*v) %*% Fx))
  
val <- exp_Fu * exp_Fv - exp_Fuv^2
val. <- 0

for(k1 in 1:(L-1)){
  for(k2 in (k1+1):L){
    val. <- val. + (exp(1/2 * (sum(u*Fx[,k1])+sum(v*Fx[,k2]))) - exp(1/2*(sum(u*Fx[,k2]) + sum(v*Fx[,k1]))))^2
  }
}
val
val.
```
## 証明(できるか？)

$$
\psi(\Theta) = \log{\sum_{i=1}^L exp(\sum_{j=1}^N f_{j,i} \times \theta_j)}
$$

任意の点 $X_0$を通り、方向 $V$の２階の微分は

$$
\Theta' = \Theta - X_0
$$
という平行移動をし(変数変換をし)、

正規直交基底 E による回転 R (回転 R による変数変換)をし、その第一軸方向の二階の微分をすることに相当するから...

$$
\Theta'' = R \Theta
$$

回転 R の制約が面倒なので、さらに制約を緩めて、

平行移動$(d_1,...,d_N)$　+ 線形変換$\begin{pmatrix} s_{i,j} \end{pmatrix}$ ($N \times N$ 行列)とする。

$$
(\Theta,1)^T  = \left[\begin{array}{ccc|c}s_{1,1} & ... & s_{1,N}  & d_1  \\ ... & ... & ...  & ...  \\ s_{N,1} & ... & s_{N,N}  & d_N  \\\hline 0 & ... & ... & 1  \end{array}\right] (\Theta'',1)^T
$$

$$
\theta_j = \sum_{k=1}^N s_{j,k} \theta_j '' + d_j
$$

ポテンシャル関数を変数変換する。

$$
\psi(\Theta) = \log{\sum_{i=1}^L exp(\sum_{j=1}^N f_{j,i} \times \theta_j)}\\
= \psi(\Theta'')\\
= \log{\sum_{i=1}^L exp(\sum_{j=1}^N f_{j,i} \times (\sum_{k=1}^N s_{j,k} \theta_k '' + d_j))}\\
= \log{ \sum_{i=1}^L exp(\sum_{j=1}^N \sum_{k=1}^N (f_{j,i} s_{j,k} \theta''_k) + \sum_{j=1}^N f_{j,i} d_j)}\\
\log{ \sum_{i=1}^L exp(\sum_{k=1}^N \theta''_k \times \sum_{j=1}^N (f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j)}
$$

これを$\theta_1''$で二階微分しても、一般性を失わないから、以下の符号を調べることにする。


$$
\frac{\partial^2}{\partial \theta_1''^2} \psi(\Theta'')\\
= \frac{\partial^2}{\partial \theta_1''^2} (\log{ \sum_{i=1}^L exp(\sum_{k=1}^N \theta''_k \times \sum_{j=1}^N (f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j)})
$$

まず、１階。
$$
\frac{\partial}{\partial \theta_1''} \psi(\Theta'')\\
= \frac{\partial}{\partial \theta_1''} (\log{ \sum_{i=1}^L exp(\sum_{k=1}^N \theta''_k \times \sum_{j=1}^N (f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j)})\\
= \frac{\sum_{i=1}^L ( (\sum_{j=1}^N f_{j,i} s_{j,k=1} ) \times exp(\sum_{k=1}^N \theta''_k \times (\sum_{j=1}^N f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j))}{ \sum_{i=1}^L exp(\sum_{k=1}^N \theta''_k \times \sum_{j=1}^N (f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j)}
$$


。。。挫折した・・・。


$$
\frac{\partial^2}{\partial \theta_1''^2} \psi(\Theta'')\\
= \frac{\sum_{i=1}^L ( (\sum_{j=1}^N f_{j,i} s_{j,k=1} )^2 \times exp(\sum_{k=1}^N \theta''_k \times (\sum_{j=1}^N f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j))}{ \sum_{i=1}^L exp(\sum_{k=1}^N \theta''_k \times \sum_{j=1}^N (f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j)}\\
- \frac{(\sum_{i=1}^L  (\sum_{j=1}^N f_{j,i} s_{j,k=1} ) \times exp(\sum_{k=1}^N \theta''_k \times (\sum_{j=1}^N f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j))^2}{ (\sum_{i=1}^L exp(\sum_{k=1}^N \theta''_k \times \sum_{j=1}^N (f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j))^2} \\
=\frac{1}{(\sum_{i=1}^L exp(\sum_{k=1}^N \theta''_k \times \sum_{j=1}^N (f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j))^2} \times \\
((\sum_{i=1}^L exp(\sum_{k=1}^N \theta''_k \times \sum_{j=1}^N (f_{j,i} s_{j,k} )
+ \sum_{j=1}^N f_{j,i} d_j)) \times (\sum_{i=1}^L ( (\sum_{j=1}^N f_{j,i} s_{j,k=1} )^2 \times exp(\sum_{k=1}^N \theta''_k \times (\sum_{j=1}^N f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j))) \\
- (\sum_{i=1}^L  (\sum_{j=1}^N f_{j,i} s_{j,k=1} ) \times exp(\sum_{k=1}^N \theta''_k \times (\sum_{j=1}^N f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j))^2)\\

= \frac{1}{(\sum_{i=1}^L exp(\sum_{k=1}^N \theta''_k \times \sum_{j=1}^N (f_{j,i} s_{j,k} ) + \sum_{j=1}^N f_{j,i} d_j))^2} \times \\ \sum{i,j; i \ne j} ( - )^2 exp_i exp_j > 0



$$